{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Second part of laboratories were conducted by <a href=\"https://github.com/jarek-pawlowski\">Jarosław Pawłowski</a>. He created notebooks we used in laboratories. I am really glad that I had him as a tutor.\n",
    "\n",
    "In second course of ML/AI we were build ML models using pytorch.\n",
    "\n",
    "In this notebook I will present only some task we had as a homework from notebook."
   ],
   "id": "f325641cb5bf5e76"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "model_args = {}\n",
    "# random seed\n",
    "model_args['seed'] = 123\n",
    "# we will use batch size of 128 in Stochastic Gradient Descent (SGD) optimization of the network\n",
    "model_args['batch_size'] = 128\n",
    "# learning rate is how fast it will descend\n",
    "model_args['lr'] = 2.e-4\n",
    "# the number of epochs is the number of times you go through the full dataset\n",
    "model_args['epochs'] = 50\n",
    "# GAN parameters:\n",
    "model_args['latent_space_dim'] = 100\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load the MINST dataset via torchvision\n",
    "transform = transforms.ToTensor()\n",
    "train_subset = datasets.MNIST('../data', train=True, download=True, transform=transform)"
   ],
   "id": "94c6dab0e3f365d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# define dataloaders\n",
    "loader_kwargs = {'batch_size': model_args['batch_size'],\n",
    "                 'num_workers': 6,\n",
    "                 'pin_memory': True,\n",
    "                 'shuffle': True}\n",
    "train_loader = torch.utils.data.DataLoader(train_subset, **loader_kwargs)"
   ],
   "id": "1ff416c0ce2911c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), 64, 7, 7)\n",
    "\n",
    "class GAN(nn.Module):\n",
    "    # this defines the generator and discriminator structures\n",
    "    def __init__(self, latent_space_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.latent_space_dim = latent_space_dim\n",
    "\n",
    "        self.generator = nn.Sequential(\n",
    "\n",
    "            nn.Linear(self.latent_space_dim, 3136, bias=False),\n",
    "            nn.BatchNorm1d(num_features=3136),\n",
    "            nn.LeakyReLU(inplace=True, negative_slope=0.0001),\n",
    "            Reshape(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=(3, 3), stride=(2, 2), padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.LeakyReLU(inplace=True, negative_slope=0.0001),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=(3, 3), stride=(2, 2), padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.LeakyReLU(inplace=True, negative_slope=0.0001),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=(3, 3), stride=(1, 1), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=8),\n",
    "            nn.LeakyReLU(inplace=True, negative_slope=0.0001),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=(2, 2), stride=(1, 1), padding=0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, padding=1, kernel_size=(3, 3), stride=(2, 2), bias=False),\n",
    "            nn.BatchNorm2d(num_features=8),\n",
    "            nn.LeakyReLU(inplace=True, negative_slope=0.0001),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "\n",
    "            nn.Conv2d(in_channels=8, out_channels=32, padding=1, kernel_size=(3, 3), stride=(2, 2), bias=False),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.LeakyReLU(inplace=True, negative_slope=0.0001),\n",
    "            #nn.Dropout2d(p=0.2),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            nn.Linear(7*7*32, 1),\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def generator_forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def discriminator_forward(self, img):\n",
    "        return self.discriminator(img).view(-1)\n"
   ],
   "id": "eba7a67e8246f132"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(model, device, train_loader, optimizer_gen, optimizer_dis, epoch_number, latent_space_dim):\n",
    "    model.train()\n",
    "    gen_losses = []\n",
    "    dis_losses = []\n",
    "    # get subsequent batches over the data in a given epoch\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        # normalize images to [-1, 1] range\n",
    "        data = data*2. - 1.\n",
    "        batch_size = data.size(0)\n",
    "        # send data tensors to GPU (or CPU)\n",
    "        data = data.to(device)\n",
    "        # labels for training discriminator\n",
    "        valid = torch.ones(batch_size).float().to(device)\n",
    "        fake = torch.zeros(batch_size).float().to(device)\n",
    "        # --------------------------\n",
    "        # Train Generator\n",
    "        # --------------------------\n",
    "        # this will zero out the gradients for this batch\n",
    "        optimizer_gen.zero_grad()\n",
    "        # generate new images from noise\n",
    "        z = torch.zeros((batch_size, latent_space_dim)).uniform_(-1.0, 1.0).to(device)\n",
    "        generated_images = model.generator_forward(z)\n",
    "        # loss for fooling the discriminator\n",
    "        dis_predictions = model.discriminator_forward(generated_images.view(batch_size, 1, 28, 28))\n",
    "        #\n",
    "        gen_loss = F.binary_cross_entropy_with_logits(dis_predictions, valid) # not fooling D increases G loss\n",
    "        gen_loss.backward()\n",
    "        optimizer_gen.step()\n",
    "        gen_losses.append(gen_loss.item())\n",
    "        # --------------------------\n",
    "        # Train Discriminator\n",
    "        # --------------------------\n",
    "        # this will zero out the gradients for this batch\n",
    "        optimizer_dis.zero_grad()\n",
    "        # D predictions for real images\n",
    "        dis_predictions_real = model.discriminator_forward(data.view(batch_size, 1, 28, 28))\n",
    "        real_loss = F.binary_cross_entropy_with_logits(dis_predictions_real, valid) # D should classify real as valid\n",
    "        # D predictions for generated images\n",
    "        dis_predictions_fake = model.discriminator_forward(generated_images.view(batch_size, 1, 28, 28).detach())\n",
    "        fake_loss = F.binary_cross_entropy_with_logits(dis_predictions_fake, fake) # D should classify generated as fake\n",
    "        #\n",
    "        dis_loss = 0.5*(real_loss + fake_loss)\n",
    "        dis_loss.backward()\n",
    "        optimizer_dis.step()\n",
    "        dis_losses.append(dis_loss.item())\n",
    "\n",
    "    return gen_losses, dis_losses\n",
    "\n",
    "\n",
    "def plot_loss(gen_loss, dis_loss, title=None):\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"subsequent epochs\")\n",
    "    plt.ylabel('loss')\n",
    "    xlabels = np.linspace(0, model_args['epochs'], num=len(gen_loss), endpoint=True)\n",
    "    plt.plot(xlabels, gen_loss, label='generator')\n",
    "    plt.plot(xlabels, dis_loss, label='discriminator')\n",
    "    plt.legend()\n",
    "    if title is not None: plt.title(title)\n",
    "    plt.show()"
   ],
   "id": "5c90ee3c67a450d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tasks to do\n",
    "* what if we increase/decrease the latent space size;\n",
    "* please observe what will happen to generated image if we make a continuous transition (vector space arithmetic) between two given configurations in the latent space;"
   ],
   "id": "f8f0660596d18fe6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Increase latent space",
   "id": "a44a3c32520761d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GAN(2*model_args['latent_space_dim']).to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer_gen = torch.optim.Adam(model.generator.parameters(), lr=model_args['lr'])\n",
    "optimizer_dis = torch.optim.Adam(model.discriminator.parameters(), lr=model_args['lr'])"
   ],
   "id": "d00db4e0f5eca08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = model.to(device)\n",
    "summary(model.generator, input_size=(200,))\n",
    "summary(model.discriminator, input_size=(1, 28, 28))"
   ],
   "id": "95bee0d4a4c13ff8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(model_args['seed'])\n",
    "generator_loss = []\n",
    "discriminator_loss = []\n",
    "for epoch_number in range(1, model_args['epochs'] + 1):\n",
    "    gen_losses, dis_losses = train(model, device, train_loader, optimizer_gen, optimizer_dis, epoch_number, 2*model_args['latent_space_dim'])\n",
    "    print('Train Epoch {} | Generator loss = {:.4f} | Discriminator loss = {:.4f}'.format(\n",
    "        epoch_number, np.mean(gen_losses), np.mean(dis_losses)))\n",
    "    generator_loss.extend(gen_losses)\n",
    "    discriminator_loss.extend(dis_losses)\n",
    "\n",
    "plot_loss(generator_loss, discriminator_loss)"
   ],
   "id": "83d9f05b59c6d5ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "\n",
    "z = torch.zeros((25, model_args['latent_space_dim']*2)).uniform_(-1.0, 1.0).to(device)\n",
    "generated_images = model.generator_forward(z)\n",
    "imgs = generated_images.view(-1, 28, 28)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize=(7,7), tight_layout=True)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axs[i,j].imshow(imgs[i*5+j].to(torch.device('cpu')).detach(), cmap='binary')\n"
   ],
   "id": "9e62f787299a9031"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Decrease latent space",
   "id": "f4c1e33d6a18f3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GAN(int(model_args['latent_space_dim']/2)).to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer_gen = torch.optim.Adam(model.generator.parameters(), lr=model_args['lr'])\n",
    "optimizer_dis = torch.optim.Adam(model.discriminator.parameters(), lr=model_args['lr'])"
   ],
   "id": "a9de993377103f1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = model.to(device)\n",
    "summary(model.generator, input_size=(50,))\n",
    "summary(model.discriminator, input_size=(1, 28, 28))"
   ],
   "id": "7b5a30522acb6385"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(model_args['seed'])\n",
    "generator_loss = []\n",
    "discriminator_loss = []\n",
    "for epoch_number in range(1, model_args['epochs'] + 1):\n",
    "    gen_losses, dis_losses = train(model, device, train_loader, optimizer_gen, optimizer_dis, epoch_number, int(model_args['latent_space_dim']/2))\n",
    "    print('Train Epoch {} | Generator loss = {:.4f} | Discriminator loss = {:.4f}'.format(\n",
    "        epoch_number, np.mean(gen_losses), np.mean(dis_losses)))\n",
    "    generator_loss.extend(gen_losses)\n",
    "    discriminator_loss.extend(dis_losses)\n",
    "\n",
    "plot_loss(generator_loss, discriminator_loss)"
   ],
   "id": "85dd84e1ccd890b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "\n",
    "z = torch.zeros((25, int(model_args['latent_space_dim']/2))).uniform_(-1.0, 1.0).to(device)\n",
    "generated_images = model.generator_forward(z)\n",
    "imgs = generated_images.view(-1, 28, 28)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize=(7,7), tight_layout=True)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axs[i,j].imshow(imgs[i*5+j].to(torch.device('cpu')).detach(), cmap='binary')"
   ],
   "id": "a4dc3f9dad34e8c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
