{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Second part of laboratories were conducted by <a href=\"https://github.com/jarek-pawlowski\">Jarosław Pawłowski</a>. He created notebooks we used in laboratories. I am really glad that I had him as a tutor.\n",
    "\n",
    "In second course of ML/AI we were build ML models using pytorch.\n",
    "\n",
    "In this notebook I will present only some task we had as a homework from notebook."
   ],
   "id": "65ef2006153fffd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 14})"
   ],
   "id": "7cce8972699aa630"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tasks to do\n",
    "* try to learn neural network adding two binary numbers or performing multiplication by *two*,\n",
    "* what would happened if we changed input function to `sin(70*x)*exp(x)`, how to fix this?"
   ],
   "id": "2bb01bca6fb124b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Adding three binary numbers",
   "id": "b3d3df5a5dfb258c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define basic logic gates\n",
    "\n",
    "# labels\n",
    "#Y_or = torch.tensor([0, 1, 1, 1], dtype=torch.float32).view(-1, 1)\n",
    "#Y_and = torch.tensor([0, 0, 0, 1], dtype=torch.float32).view(-1, 1)\n",
    "#Y_xor = torch.tensor([0, 1, 1, 0], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# let's define a model\n",
    "class Perceptron(torch.nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, size):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.single_neuron = nn.Linear(3, size)\n",
    "        self.hidden_layer_1st = nn.Linear(size, size)\n",
    "        self.output_layer = nn.Linear(size, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # method called once the model is executed\n",
    "    def forward(self, x):\n",
    "        x = self.single_neuron(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.hidden_layer_1st(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output_layer(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "# define model and learnig scheme\n",
    "model = Perceptron(size=6)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
    "MSE = nn.MSELoss()\n",
    "\n",
    "# train\n",
    "N_epochs = 10000\n",
    "\n",
    "train_loss = []\n",
    "model.train()  # turn on the training mode\n",
    "#[bit_from_first_num, bit_from_sec_num, carry]\n",
    "X = torch.tensor([[0,0,0], [0,0,1], [0,1,0], [0,1,1], [1,0,0], [1,0,1], [1,1,0], [1,1,1]], dtype=torch.float32)\n",
    "#[carry, normal]\n",
    "Y = torch.tensor([[0,0], [0,1], [0,1], [1,0], [0,1], [1,0], [1,0], [1,1]], dtype=torch.float32)\n",
    "for _ in range(N_epochs):\n",
    "        # this will zero out the gradients for this batch\n",
    "    optimizer.zero_grad()\n",
    "        # make predictions\n",
    "    y_pred = model(X)\n",
    "        # calculate the MSE loss\n",
    "    loss = MSE(y_pred, Y)\n",
    "        # backpropagate the loss\n",
    "    loss.backward()\n",
    "        # update the model weights (with assumed learning rate)\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item())\n",
    "print(\"last loss value = \", train_loss[-1])\n",
    "model.eval()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for i, [x, y] in enumerate(zip(X,Y)):\n",
    "  print()\n",
    "  print(str(x[0]) + \"+\" + str(x[1]) + \"+\" + str(x[2]) +\"->\"+ str(model(x))+\" real answer: \"+ str(y))"
   ],
   "id": "2f24a151b44141a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def adding_two_binary_numbers(first_number : str, second_number:str, model):\n",
    "  if len(first_number) != len(second_number):\n",
    "    print(\"Binary numbers should have the same length\")\n",
    "    return -1\n",
    "  carry = 0\n",
    "  first_number = first_number[::-1]\n",
    "  second_number = second_number[::-1]\n",
    "  result_number = \"\"\n",
    "  for first_number_bit, second_number_bit in zip(first_number, second_number):\n",
    "    first_number_bit = int(first_number_bit)\n",
    "    second_number_bit = int(second_number_bit)\n",
    "    X = torch.tensor([[first_number_bit, second_number_bit,carry]], dtype=torch.float32)\n",
    "    y_pred = model(X).detach().numpy()[0]\n",
    "    carry, bit = int(np.round(y_pred[0])), int(np.round(y_pred[1]))\n",
    "    result_number = result_number + str(bit)\n",
    "  result_number = result_number + str(carry)\n",
    "  return result_number[::-1]\n",
    "\n"
   ],
   "id": "61f7f029cacbd845"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "little test",
   "id": "3508a367236b7f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "first = '11'\n",
    "second = '01'\n",
    "result = adding_two_binary_numbers(first, second, model)\n",
    "print(result)"
   ],
   "id": "3cdfdd4e2d423c06"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Bigger test",
   "id": "56ed89ca5e61beb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def test_of_function_and_model(number_of_bits: int, model):\n",
    "  max_number = 2**number_of_bits\n",
    "  number_of_correct = 0\n",
    "  for i in range(max_number):\n",
    "    for j in range(max_number):\n",
    "      first_number = np.binary_repr(i, width=number_of_bits)\n",
    "      second_number = np.binary_repr(j, width=number_of_bits)\n",
    "      result = adding_two_binary_numbers(first_number, second_number, model)\n",
    "      true_result = np.binary_repr(i+j, width=number_of_bits+1)\n",
    "      if result == true_result:\n",
    "        number_of_correct +=1\n",
    "  return number_of_correct / (max_number**2)"
   ],
   "id": "7f20883b27ebad79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "result = test_of_function_and_model(5, model)\n",
    "print(result)"
   ],
   "id": "8553182999d4a6c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating function: sin(70*x)*exp(x),\n",
   "id": "2dbf6c1a30d69701"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X = torch.arange(-1.5, 1.5, 0.05).view(-1, 1).type(torch.float32)\n",
    "y = torch.sin(X*70.)*torch.exp(X)\n",
    "plt.plot(X, y, 'g')\n",
    "plt.show()"
   ],
   "id": "5031bea6b64ddb95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Normalize",
   "id": "7867ab6a065feb6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y = y/np.max(y.detach().numpy())\n",
    "plt.plot(X, y, 'g')\n",
    "plt.show()"
   ],
   "id": "840316600d41ce44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class PerceptronDeepV2(torch.nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, hidden_size):\n",
    "        super(PerceptronDeepV2, self).__init__()\n",
    "        self.first_hidden_layer = nn.Linear(1, hidden_size)\n",
    "        self.second_hidden_layer = nn.Linear(hidden_size, 2*hidden_size)\n",
    "        self.third_hidden_layer = nn.Linear(2*hidden_size, 3*hidden_size)\n",
    "        self.forth_hidden_layer = nn.Linear(3*hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)\n",
    "        self.activation = nn.Tanh()  # Sigmoid has non-negative values\n",
    "    # mathod called once the model is executed\n",
    "    def forward(self, x):\n",
    "        x = self.first_hidden_layer(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.second_hidden_layer(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.third_hidden_layer(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.forth_hidden_layer(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output_layer(x)\n",
    "        return self.activation(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# narrow model\n",
    "model = PerceptronDeepV2(hidden_size=20).to(device)\n",
    "X, y = X.to(device), y.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.2)\n",
    "MSE = nn.MSELoss()\n",
    "\n",
    "# train\n",
    "N_epochs = 75000\n",
    "train_loss = []\n",
    "model.train()  # turn on the training mode\n",
    "for _ in range(N_epochs):\n",
    "    # this will zero out the gradients for this batch\n",
    "    optimizer.zero_grad()\n",
    "    # make predictions\n",
    "    y_pred = model(X)\n",
    "    # calculate the MSE loss\n",
    "    loss = MSE(y_pred, y)\n",
    "    # backpropagate the loss\n",
    "    loss.backward()\n",
    "    # update the model weights (with assumed learning rate)\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item())\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "model.eval()\n",
    "plt.plot(X.cpu(), model(X).cpu().detach())\n",
    "plt.plot(X.cpu(), y.cpu(), 'g')\n",
    "plt.xlabel('x')\n",
    "plt.show()"
   ],
   "id": "9b023478df82aa3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Poor performance mainly because the input data have to little number of points -> so add points",
   "id": "4b8ccce8ccf22691"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X = torch.arange(-1.5, 1.5, 0.01).view(-1, 1).type(torch.float32)\n",
    "y = torch.sin(X*70.)*torch.exp(X)\n",
    "plt.plot(X, y, 'g')\n",
    "plt.show()"
   ],
   "id": "58b7e91539cd8dbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class PerceptronDeep(torch.nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, hidden_size):\n",
    "        super(PerceptronDeep, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(1, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)\n",
    "        self.activation = nn.Tanh()  # Sigmoid has non-negative values\n",
    "    # mathod called once the model is executed\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# narrow model\n",
    "model = PerceptronDeep(hidden_size=300)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.1)\n",
    "MSE = nn.MSELoss()\n",
    "print(len(X))\n",
    "# train\n",
    "N_epochs = 175000\n",
    "train_loss = []\n",
    "model.train()  # turn on the training mode\n",
    "for _ in range(N_epochs):\n",
    "    # this will zero out the gradients for this batch\n",
    "    optimizer.zero_grad()\n",
    "    # make predictions\n",
    "    y_pred = model(X)\n",
    "    # calculate the MSE loss\n",
    "    loss = MSE(y_pred, y)\n",
    "    # backpropagate the loss\n",
    "    loss.backward()\n",
    "    # update the model weights (with assumed learning rate)\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item())\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel('epoch')\n",
    "#plt.ylim([0,1000])\n",
    "plt.show()\n",
    "\n",
    "model.eval()\n",
    "plt.plot(X.numpy(), model(X).detach().numpy())\n",
    "plt.plot(X.numpy(), y.numpy(), 'g')\n",
    "plt.xlabel('x')\n",
    "plt.show()"
   ],
   "id": "fef64e858dfc4980"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
